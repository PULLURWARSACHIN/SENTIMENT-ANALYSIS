# -*- coding: utf-8 -*-
"""SENTIMENT ANALYSIS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13kCt8bHIvRZxTcGZQoH9mlaI8RMnkJuN
"""

pip install Tokenizer

pip install Tensorflow

pip install Keras-Preprocessing

import pandas as pd
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.text import Tokenizer

from google.colab import files
files.upload()

df = pd.read_csv('Tweets.csv')

review_df = df[['text','airline_sentiment']]
review_df.head()

review_df = review_df[review_df['airline_sentiment']!='neutural']
review_df.head()

review_df["airline_sentiment"].value_counts()

sentiment_label = review_df.airline_sentiment.factorize()
sentiment_label

tweet = review_df.text.values

tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(tweet)
vocab_size=len(tokenizer.word_index)+1

from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(tweet)

encoded_docs = tokenizer.texts_to_sequences(tweet)

from tensorflow.keras.preprocessing.sequence import pad_sequences
padded_sequence = pad_sequences(encoded_docs,maxlen=200)

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import LSTM,Dense,Dropout,SpatialDropout1D
from tensorflow.keras.layers import Embedding

embedding_vector_length = 32
model = Sequential()
model.add(Embedding(vocab_size,embedding_vector_length,input_length=200))
model.add(SpatialDropout1D(0.25))
model.add(LSTM(50,dropout=0.5,recurrent_dropout=0.5))
model.add(Dropout(0.2))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
print(model.summary())

history = model.fit(padded_sequence,sentiment_label[0],validation_split=0.2,epochs=5,batch_size=32)

plt.plot(history.history['accuracy'],label='acc')
plt.plot(history.history['val_accuracy'],label='val_acc')
plt.legend()
plt.show()
plt.savefig("Accuracy plot.jpg")

plt.plot(history.history['loss'],label='loss')
plt.plot(history.history['val_loss'],label='val_loss')
plt.legend()
plt.show()
plt.savefig("loss plot.jpg")

def predict_sentiment(text):
  tw = tokenizer.texts_to_sequences([text])
  tw = pad_sequences(tw,maxlen=200)
  prediction = int(model.predict(tw).round().item())
  print("Predicted label:",sentiment_label[1][prediction])

test_sentence1 = " I had enjoyed my journey in this flight"
predict_sentiment(test_sentence1)

test_sentence2 = "This is the best flight experience of my life!"
predict_sentiment(test_sentence2)